<!-- Figures Section: Real-time Houbara Analysis -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <h2 class="title has-text-centered">Real-Time Houbara Analysis</h2>
    <p class="subtitle has-text-justified">
      (a) Input images (first, fourth, and seventh rows). 
      (b) Predicted instance segmentation masks by MobileSAM (second, fifth, and eighth rows).
      (c) Combined view: Input images with object detections (bounding boxes) and MobileSAM segmentation masks (third, sixth, and ninth rows).
    </p>
    <div class="image-container">
      <img src="images/real_time_houbara_analysis.png" alt="Real-time Houbara Analysis">
    </div>
  </div>
</section>

<!-- Figures Section: Segmentation Comparison -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <h2 class="title has-text-centered">Qualitative Comparison of Segmentation Results</h2>
    <p class="subtitle has-text-justified">
      This figure presents a qualitative comparison of segmentation performance across various models. 
      Each column displays: 
      (a) Input Images, (b) Ground Truth Annotations, (c) DeepLabV3 Results, (d) FCN Results, 
      (e) LRASPP Results, (f) MobileSAM Baseline Results, (g) YOLOv9+MobileSAM Results, and 
      (h) Overlapping Results of YOLOv10+MobileSAM with Input Images. 
      The overlapping panel highlights the superior object localization and segmentation precision achieved by YOLOv10+MobileSAM.
    </p>
    <div class="image-container">
      <img src="images/segmentation_comparison.png" alt="Qualitative Segmentation Comparison">
    </div>
  </div>
</section>

<!-- Styling for Images -->
<style>
  .image-container {
    display: flex;
    justify-content: center;
    align-items: center;
    margin-top: 15px;
  }

  .image-container img {
    width: 60%; /* Adjust image size */
    max-width: 600px;
    border-radius: 8px;
    display: block;
  }
</style>
